{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Alex's Home Assistant documentation This website contains reference documentation to my Home Assistant installation. I will try and contain all my IMHO extensive Home Assistant knowledge within this repo. Hopefully it can be as a reference to you. Issues, questions and pull requests are welcome! History Before starting with Home Assistant in november 2018, I used a Raspberry Pi 3B+ with Domoticz for a fairly simple home automation setup. Although it worked great, Domoticz was quite lacking with new integrations and updates. So I dived, head first into Home Assistant on version 0.81. The initial migration was quite tricky, but after a long week of trial and error, I haven't looked back since... Since than I migrated to an Intel NUC like device, expanded my Z-Wave network and added Zigbee devices, contributed to Home Assistant and even created my own Home Assistant add-ons . Hardware Over the last few years I collected and succesfully implemented multiple devices which are essential to my home automation. I will try and list all of these devices and provide more information where necessary. Host system Since my Raspberry Pi 3B+, I've migrated to a Intel NUC-like device, the Gigabyte Brix GB-BLCE-4105 . I've elaborated on why I chose this system and how to install this on a dedicated page . Wi-Fi devices tbd. Zigbee devices tbd. Z-Wave devices tbd. Software Home assistant custom components tbd. Home Assistant add-ons AdGuard Home Bitwarden secrets for Home Assistant Bitwarden RS Check Home Assistant configuration Git pull InfluxDB MariaDB Plex Media Server Rclone Samba share Tautulli Traefik WireGuard deCONZ Home Assistant integrations tbd.","title":"Home"},{"location":"#alexs-home-assistant-documentation","text":"This website contains reference documentation to my Home Assistant installation. I will try and contain all my IMHO extensive Home Assistant knowledge within this repo. Hopefully it can be as a reference to you. Issues, questions and pull requests are welcome!","title":"Alex's Home Assistant documentation"},{"location":"#history","text":"Before starting with Home Assistant in november 2018, I used a Raspberry Pi 3B+ with Domoticz for a fairly simple home automation setup. Although it worked great, Domoticz was quite lacking with new integrations and updates. So I dived, head first into Home Assistant on version 0.81. The initial migration was quite tricky, but after a long week of trial and error, I haven't looked back since... Since than I migrated to an Intel NUC like device, expanded my Z-Wave network and added Zigbee devices, contributed to Home Assistant and even created my own Home Assistant add-ons .","title":"History"},{"location":"#hardware","text":"Over the last few years I collected and succesfully implemented multiple devices which are essential to my home automation. I will try and list all of these devices and provide more information where necessary.","title":"Hardware"},{"location":"#host-system","text":"Since my Raspberry Pi 3B+, I've migrated to a Intel NUC-like device, the Gigabyte Brix GB-BLCE-4105 . I've elaborated on why I chose this system and how to install this on a dedicated page .","title":"Host system"},{"location":"#wi-fi-devices","text":"tbd.","title":"Wi-Fi devices"},{"location":"#zigbee-devices","text":"tbd.","title":"Zigbee devices"},{"location":"#z-wave-devices","text":"tbd.","title":"Z-Wave devices"},{"location":"#software","text":"","title":"Software"},{"location":"#home-assistant-custom-components","text":"tbd.","title":"Home assistant custom components"},{"location":"#home-assistant-add-ons","text":"AdGuard Home Bitwarden secrets for Home Assistant Bitwarden RS Check Home Assistant configuration Git pull InfluxDB MariaDB Plex Media Server Rclone Samba share Tautulli Traefik WireGuard deCONZ","title":"Home Assistant add-ons"},{"location":"#home-assistant-integrations","text":"tbd.","title":"Home Assistant integrations"},{"location":"add-ons/bitwarden/","text":"Bitwarden secrets for Home Assistant set up This page outlines my personal set up with Bitwarden secrets for Home Assistant . Bitwarden installation You can easily install Bitwarden RS for Home Assistant from the Add-on Store. Bitwarden is a community maintained add-on available from the Home Assistant Community Add-ons repository. Home Assistant organization We need to do some basic management with Bitwarden to set it up for usage with Home Assistant. This is all done through the Bitwarden web interface. Creating your personal user After installing and starting the Bitwarden RS add-on, I recommend that you create your personal user. With this user you can use Bitwarden in general from any device. Creating a Home Assistant user We are also going to create a Home Assistant user. This user is only needed by Home Assistant. Since we have a local Bitwarden installation I recommend setting the user id / e-mail address to: homeassistant@localhost.lan indicating this is a local user only. You can use the Bitwarden password generator to generate a secure password for this user. Disable new registrations When you have Bitwarden exposed to the internet (ie. through a reverse proxy like Traefik ) I recommend disabling new user registration after you have created all of your users. This will keep unwelcome guests out of our local install. You can do this by browsing to the Bitwarden RS suffixed by the /admin/ path. So for instance: 'http://192.168.0.10:7878/admin/'. To access the admin panel you will need your personal access token which can be found in the add-on log. If the admin token isn't visible (anymore) in the Bitwarden RS log you can also retrieve it through Docker and SSH with the following command: docker exec -it addon_a0d7b954_bitwarden cat /data/config.json | jq -r '.admin_token' This will print your admin token. Note This is an optional step. Creating a Home Assistant organization entity Finally we are going to create a Home Assistant organization in which we can easily manage our Home Assistant secrets. First we are going to go to Settings \u27a1 Organizations and click New Organization . We set the Organization Name to Home Assistant and you can set anything in Billing email . After creating, we go to this newly created organization and click the Manage tab. We are going to invite our earlier created Home Assistant user by clicking the \u2795 Invite User tab. Note We want this user to have access to all items! Finally we are going to confirm this user to have access to our Home Assistant organization. The user should automatically already have accepted the invite. Now we are done with setting up the correct environment for Home Assistant to retrieve our secrets. Adding secrets Adding secrets for use in Home Assistant is fairly trivial. You can add items through the web interface or through any of Bitwarden's apps. The only thing you should take care of is adding the item to the correct organization. Installing Bitwarden secrets for Home Assistant Follow these steps to get the add-on installed on your system: Navigate in your Home Assistant frontend to Supervisor -> Add-on Store Add this new repository by URL ( https://github.com/alex3305/home-assistant-addons ) Find the \"Bitwarden secrets for Home Assistant\" add-on and click it. Click on the \"INSTALL\" button Configuration Just fill in your Home Assistant Bitwarden user, password and organization name into the add-on and you are good to go. You can also enable repeat mode, which will retrieve your secrets at every interval automatically without the need to restart the add-on.","title":"Bitwarden"},{"location":"add-ons/bitwarden/#bitwarden-secrets-for-home-assistant-set-up","text":"This page outlines my personal set up with Bitwarden secrets for Home Assistant .","title":"Bitwarden secrets for Home Assistant set up"},{"location":"add-ons/bitwarden/#bitwarden-installation","text":"You can easily install Bitwarden RS for Home Assistant from the Add-on Store. Bitwarden is a community maintained add-on available from the Home Assistant Community Add-ons repository.","title":"Bitwarden installation"},{"location":"add-ons/bitwarden/#home-assistant-organization","text":"We need to do some basic management with Bitwarden to set it up for usage with Home Assistant. This is all done through the Bitwarden web interface.","title":"Home Assistant organization"},{"location":"add-ons/bitwarden/#creating-your-personal-user","text":"After installing and starting the Bitwarden RS add-on, I recommend that you create your personal user. With this user you can use Bitwarden in general from any device.","title":"Creating your personal user"},{"location":"add-ons/bitwarden/#creating-a-home-assistant-user","text":"We are also going to create a Home Assistant user. This user is only needed by Home Assistant. Since we have a local Bitwarden installation I recommend setting the user id / e-mail address to: homeassistant@localhost.lan indicating this is a local user only. You can use the Bitwarden password generator to generate a secure password for this user.","title":"Creating a Home Assistant user"},{"location":"add-ons/bitwarden/#disable-new-registrations","text":"When you have Bitwarden exposed to the internet (ie. through a reverse proxy like Traefik ) I recommend disabling new user registration after you have created all of your users. This will keep unwelcome guests out of our local install. You can do this by browsing to the Bitwarden RS suffixed by the /admin/ path. So for instance: 'http://192.168.0.10:7878/admin/'. To access the admin panel you will need your personal access token which can be found in the add-on log. If the admin token isn't visible (anymore) in the Bitwarden RS log you can also retrieve it through Docker and SSH with the following command: docker exec -it addon_a0d7b954_bitwarden cat /data/config.json | jq -r '.admin_token' This will print your admin token. Note This is an optional step.","title":"Disable new registrations"},{"location":"add-ons/bitwarden/#creating-a-home-assistant-organization-entity","text":"Finally we are going to create a Home Assistant organization in which we can easily manage our Home Assistant secrets. First we are going to go to Settings \u27a1 Organizations and click New Organization . We set the Organization Name to Home Assistant and you can set anything in Billing email . After creating, we go to this newly created organization and click the Manage tab. We are going to invite our earlier created Home Assistant user by clicking the \u2795 Invite User tab. Note We want this user to have access to all items! Finally we are going to confirm this user to have access to our Home Assistant organization. The user should automatically already have accepted the invite. Now we are done with setting up the correct environment for Home Assistant to retrieve our secrets.","title":"Creating a Home Assistant organization entity"},{"location":"add-ons/bitwarden/#adding-secrets","text":"Adding secrets for use in Home Assistant is fairly trivial. You can add items through the web interface or through any of Bitwarden's apps. The only thing you should take care of is adding the item to the correct organization.","title":"Adding secrets"},{"location":"add-ons/bitwarden/#installing-bitwarden-secrets-for-home-assistant","text":"Follow these steps to get the add-on installed on your system: Navigate in your Home Assistant frontend to Supervisor -> Add-on Store Add this new repository by URL ( https://github.com/alex3305/home-assistant-addons ) Find the \"Bitwarden secrets for Home Assistant\" add-on and click it. Click on the \"INSTALL\" button","title":"Installing Bitwarden secrets for Home Assistant"},{"location":"add-ons/bitwarden/#configuration","text":"Just fill in your Home Assistant Bitwarden user, password and organization name into the add-on and you are good to go. You can also enable repeat mode, which will retrieve your secrets at every interval automatically without the need to restart the add-on.","title":"Configuration"},{"location":"add-ons/influxdb-backup/","text":"Backup and restore Manual InfluxDB backup from Home Assistant add-on We can create a manual InfluxDB backup, which can be used for backup or testing on another system. These steps use the command line and Docker to create a backup. # Let's get into the container docker exec -it addon_a0d7b954_influxdb bash # We create a temporary backup directory mkdir -p /share/backup/influxdb/ # Create the backup to our new share directory influxd backup -database homeassistant -portable /share/backup/influxdb/ # Exit the container exit # (Optional) Set so all users can read the backup data sudo chmod a+r /usr/share/hassio/share/backup/influxdb/* # (Optional) Afterwards remove the backup sudo rm -rf /usr/share/hassio/share/backup/influxdb/* Manual InfluxDB backup restore to Home Assistant add-on Restoring is also quite straight forward when you have created a portable backup. # Let's get into the container docker exec -it addon_a0d7b954_influxdb bash # Restore the backup from the afformentioned directory influxd restore -portable /share/backup/influxdb/ Manual InfluxDB backup restore to local Docker container This can be useful for testing purposes. First we create set up the Docker containers for testing. docker network create influxdb docker run -d -p 8086 :8086 -v /home/ ${ USER } /dump/influxdb:/backup --net influxdb --name influxdb influxdb docker run -d -p 8888 :8888 --net influxdb --name chronograf chronograf --influxdb-url = http://influxdb:8086 The steps above run InfluxDB with Chronograf. Chronograf provides a nice and easy to use web interface, which can be accessed on http://localhost:8888 . After we have set up InfluxDB we can restore our backup. # Create the directory where we get to store our backup mkdir -p /home/ ${ USER } /dump/influxdb cd /home/ ${ USER } /dump/influxdb # Let's retrieve our backup from Home Assistant scp homeassistant.lan:/usr/share/hassio/share/backup/influxdb/ \\* ./ # Let's get into our newly created Docker container docker exec -it influxdb bash # And restore our backup! influxd restore -portable /backup And when your done, cleaning up is easy too! # Delete the Docker containers and network docker rm -f chronograf influxdb docker network rm influxdb # Clean up our backup rm -rf /home/ ${ USER } /dump/influxdb Note These steps must be done locally.","title":"Backup and restore"},{"location":"add-ons/influxdb-backup/#backup-and-restore","text":"","title":"Backup and restore"},{"location":"add-ons/influxdb-backup/#manual-influxdb-backup-from-home-assistant-add-on","text":"We can create a manual InfluxDB backup, which can be used for backup or testing on another system. These steps use the command line and Docker to create a backup. # Let's get into the container docker exec -it addon_a0d7b954_influxdb bash # We create a temporary backup directory mkdir -p /share/backup/influxdb/ # Create the backup to our new share directory influxd backup -database homeassistant -portable /share/backup/influxdb/ # Exit the container exit # (Optional) Set so all users can read the backup data sudo chmod a+r /usr/share/hassio/share/backup/influxdb/* # (Optional) Afterwards remove the backup sudo rm -rf /usr/share/hassio/share/backup/influxdb/*","title":"Manual InfluxDB backup from Home Assistant add-on"},{"location":"add-ons/influxdb-backup/#manual-influxdb-backup-restore-to-home-assistant-add-on","text":"Restoring is also quite straight forward when you have created a portable backup. # Let's get into the container docker exec -it addon_a0d7b954_influxdb bash # Restore the backup from the afformentioned directory influxd restore -portable /share/backup/influxdb/","title":"Manual InfluxDB backup restore to Home Assistant add-on"},{"location":"add-ons/influxdb-backup/#manual-influxdb-backup-restore-to-local-docker-container","text":"This can be useful for testing purposes. First we create set up the Docker containers for testing. docker network create influxdb docker run -d -p 8086 :8086 -v /home/ ${ USER } /dump/influxdb:/backup --net influxdb --name influxdb influxdb docker run -d -p 8888 :8888 --net influxdb --name chronograf chronograf --influxdb-url = http://influxdb:8086 The steps above run InfluxDB with Chronograf. Chronograf provides a nice and easy to use web interface, which can be accessed on http://localhost:8888 . After we have set up InfluxDB we can restore our backup. # Create the directory where we get to store our backup mkdir -p /home/ ${ USER } /dump/influxdb cd /home/ ${ USER } /dump/influxdb # Let's retrieve our backup from Home Assistant scp homeassistant.lan:/usr/share/hassio/share/backup/influxdb/ \\* ./ # Let's get into our newly created Docker container docker exec -it influxdb bash # And restore our backup! influxd restore -portable /backup And when your done, cleaning up is easy too! # Delete the Docker containers and network docker rm -f chronograf influxdb docker network rm influxdb # Clean up our backup rm -rf /home/ ${ USER } /dump/influxdb Note These steps must be done locally.","title":"Manual InfluxDB backup restore to local Docker container"},{"location":"add-ons/influxdb-downsampling/","text":"InfluxDB downsampling data When you store all your sensor data from Home Assistant in InfluxDB, it will continue to grow. And of course storing all Home Assistant data is quite nice, but our data pool can exceed our disk space over time. This can be solved with using both continious queries (CQ) and retention policies (RP). Continious queries are database queries that are ran when new data is added to the database. Thus running almost continuously. We can leverage this functionality to downsample our large term data. We can also use * Retention policies on our data to let old data time out. When this happens the old data is automatically deleted from our database. Combining both of these features, we can continuously downsample and delete older fine grained data, while retainig the downsampled data. Basic queries -- Running this query will show the current continuous queries. SHOW CONTINUOUS QUERIES -- Running this query will show the current retention policies on our database. SHOW RETENTION POLICIES on \"homeassistant\" Downsampling data I started downsampling data, because my original, inifite autogen RP was filling up with about 1.5GB-2GB/year. This doesn't seem much, but I also tend to keep a couple of weeks of snapshot backups. After I have applied the CQ and RP below, I reduced my InfluxDB storage pool to about 1.3GB. Infinite retention policy Let's create an infinite retention policy within InfluxDB on our database. CREATE RETENTION POLICY \"infinite\" ON \"homeassistant\" DURATION INF REPLICATION 1 Downsample continuous query We can downsample our data quite easily by creating a continuous query. I chose to downsample to 1 hour intervals, which is more than sufficiant for me. CREATE CONTINUOUS QUERY \"cq_downsample_1h\" ON \"homeassistant\" BEGIN SELECT mean(*) INTO \"homeassistant\".\"infinite\".:MEASUREMENT FROM \"homeassistant\".\"autogen\"./.*/ GROUP BY time(1h), * FILL(previous) END Backfilling our data After creating our RP and CQ, we can than backfill our data into our newly created infinite storage. This is needed, because InfluxDB only applies our new CQ to new data. I have grouped my queries into periods of (about) 10 weeks. Otherwise it is possible to crash InfluxDB, halting our backfill. Below are the queries to backfill a year worth of data. If you have older data, you should add additional queries. SELECT mean(*) INTO \"homeassistant\".\"infinite\".:MEASUREMENT FROM \"homeassistant\".\"autogen\"./.*/ WHERE time > now() - 52w and time < now() - 40w GROUP BY time(1h), * FILL(previous) SELECT mean(*) INTO \"homeassistant\".\"infinite\".:MEASUREMENT FROM \"homeassistant\".\"autogen\"./.*/ WHERE time > now() - 41w and time < now() - 30w GROUP BY time(1h), * FILL(previous) SELECT mean(*) INTO \"homeassistant\".\"infinite\".:MEASUREMENT FROM \"homeassistant\".\"autogen\"./.*/ WHERE time > now() - 31w and time < now() - 20w GROUP BY time(1h), * FILL(previous) SELECT mean(*) INTO \"homeassistant\".\"infinite\".:MEASUREMENT FROM \"homeassistant\".\"autogen\"./.*/ WHERE time > now() - 21w and time < now() - 10w GROUP BY time(1h), * FILL(previous) SELECT mean(*) INTO \"homeassistant\".\"infinite\".:MEASUREMENT FROM \"homeassistant\".\"autogen\"./.*/ WHERE time > now() - 11w and time < now() GROUP BY time(1h), * FILL(previous) Alter autogen RP The final step in this proces is to alter our original, autogen RP to only store 26 weeks, or half a year. You can get away with a shorter RP, and even with a longer RP. For me, 26 weeks seems to be the sweet spot. ALTER RETENTION POLICY \"autogen\" on \"homeassistant\" DURATION 26w SHARD DURATION 1d DEFAULT","title":"Downsampling (RP/CQ)"},{"location":"add-ons/influxdb-downsampling/#influxdb-downsampling-data","text":"When you store all your sensor data from Home Assistant in InfluxDB, it will continue to grow. And of course storing all Home Assistant data is quite nice, but our data pool can exceed our disk space over time. This can be solved with using both continious queries (CQ) and retention policies (RP). Continious queries are database queries that are ran when new data is added to the database. Thus running almost continuously. We can leverage this functionality to downsample our large term data. We can also use * Retention policies on our data to let old data time out. When this happens the old data is automatically deleted from our database. Combining both of these features, we can continuously downsample and delete older fine grained data, while retainig the downsampled data.","title":"InfluxDB downsampling data"},{"location":"add-ons/influxdb-downsampling/#basic-queries","text":"-- Running this query will show the current continuous queries. SHOW CONTINUOUS QUERIES -- Running this query will show the current retention policies on our database. SHOW RETENTION POLICIES on \"homeassistant\"","title":"Basic queries"},{"location":"add-ons/influxdb-downsampling/#downsampling-data","text":"I started downsampling data, because my original, inifite autogen RP was filling up with about 1.5GB-2GB/year. This doesn't seem much, but I also tend to keep a couple of weeks of snapshot backups. After I have applied the CQ and RP below, I reduced my InfluxDB storage pool to about 1.3GB.","title":"Downsampling data"},{"location":"add-ons/influxdb-downsampling/#infinite-retention-policy","text":"Let's create an infinite retention policy within InfluxDB on our database. CREATE RETENTION POLICY \"infinite\" ON \"homeassistant\" DURATION INF REPLICATION 1","title":"Infinite retention policy"},{"location":"add-ons/influxdb-downsampling/#downsample-continuous-query","text":"We can downsample our data quite easily by creating a continuous query. I chose to downsample to 1 hour intervals, which is more than sufficiant for me. CREATE CONTINUOUS QUERY \"cq_downsample_1h\" ON \"homeassistant\" BEGIN SELECT mean(*) INTO \"homeassistant\".\"infinite\".:MEASUREMENT FROM \"homeassistant\".\"autogen\"./.*/ GROUP BY time(1h), * FILL(previous) END","title":"Downsample continuous query"},{"location":"add-ons/influxdb-downsampling/#backfilling-our-data","text":"After creating our RP and CQ, we can than backfill our data into our newly created infinite storage. This is needed, because InfluxDB only applies our new CQ to new data. I have grouped my queries into periods of (about) 10 weeks. Otherwise it is possible to crash InfluxDB, halting our backfill. Below are the queries to backfill a year worth of data. If you have older data, you should add additional queries. SELECT mean(*) INTO \"homeassistant\".\"infinite\".:MEASUREMENT FROM \"homeassistant\".\"autogen\"./.*/ WHERE time > now() - 52w and time < now() - 40w GROUP BY time(1h), * FILL(previous) SELECT mean(*) INTO \"homeassistant\".\"infinite\".:MEASUREMENT FROM \"homeassistant\".\"autogen\"./.*/ WHERE time > now() - 41w and time < now() - 30w GROUP BY time(1h), * FILL(previous) SELECT mean(*) INTO \"homeassistant\".\"infinite\".:MEASUREMENT FROM \"homeassistant\".\"autogen\"./.*/ WHERE time > now() - 31w and time < now() - 20w GROUP BY time(1h), * FILL(previous) SELECT mean(*) INTO \"homeassistant\".\"infinite\".:MEASUREMENT FROM \"homeassistant\".\"autogen\"./.*/ WHERE time > now() - 21w and time < now() - 10w GROUP BY time(1h), * FILL(previous) SELECT mean(*) INTO \"homeassistant\".\"infinite\".:MEASUREMENT FROM \"homeassistant\".\"autogen\"./.*/ WHERE time > now() - 11w and time < now() GROUP BY time(1h), * FILL(previous)","title":"Backfilling our data"},{"location":"add-ons/influxdb-downsampling/#alter-autogen-rp","text":"The final step in this proces is to alter our original, autogen RP to only store 26 weeks, or half a year. You can get away with a shorter RP, and even with a longer RP. For me, 26 weeks seems to be the sweet spot. ALTER RETENTION POLICY \"autogen\" on \"homeassistant\" DURATION 26w SHARD DURATION 1d DEFAULT","title":"Alter autogen RP"},{"location":"add-ons/influxdb/","text":"InfluxDB I use the InfluxDB time-series database for retaining all my sensor data. InfluxDB is a mature database with plenty of support from the Home Assistant community. Add-on configuration Installing this add-on is pretty straight forward, as it's available as an official Home Assistant add-on. I use the default settings this add-on provides. After this add-on is installed and running, I created a database and an user that has correct rights on the database. Home Assistant configuration Configuration within Home Assistant is also fairly straight forward. Just use the influxdb integration . Since we are using the add-on, we can also leverage the DNS from Home Assistant Supervisor. influxdb : host : a0d7b954-influxdb port : 8086 database : homeassistant username : homeassistant password : homeassistant max_retries : 3 default_measurement : state exclude : domains : - zwave - automation entities : - sensor.date - sensor.date_time - sensor.time As you can see, I exclude the Z-Wave and automation domains, since they can get quite verbose with a extensive setup. Also I exclude the date and time sensors, since they would log every second. Backup and restore See also InfluxDB: backup and restore . Downsampling data See also InfluxDB: downsampling .","title":"Installation"},{"location":"add-ons/influxdb/#influxdb","text":"I use the InfluxDB time-series database for retaining all my sensor data. InfluxDB is a mature database with plenty of support from the Home Assistant community.","title":"InfluxDB"},{"location":"add-ons/influxdb/#add-on-configuration","text":"Installing this add-on is pretty straight forward, as it's available as an official Home Assistant add-on. I use the default settings this add-on provides. After this add-on is installed and running, I created a database and an user that has correct rights on the database.","title":"Add-on configuration"},{"location":"add-ons/influxdb/#home-assistant-configuration","text":"Configuration within Home Assistant is also fairly straight forward. Just use the influxdb integration . Since we are using the add-on, we can also leverage the DNS from Home Assistant Supervisor. influxdb : host : a0d7b954-influxdb port : 8086 database : homeassistant username : homeassistant password : homeassistant max_retries : 3 default_measurement : state exclude : domains : - zwave - automation entities : - sensor.date - sensor.date_time - sensor.time As you can see, I exclude the Z-Wave and automation domains, since they can get quite verbose with a extensive setup. Also I exclude the date and time sensors, since they would log every second.","title":"Home Assistant configuration"},{"location":"add-ons/influxdb/#backup-and-restore","text":"See also InfluxDB: backup and restore .","title":"Backup and restore"},{"location":"add-ons/influxdb/#downsampling-data","text":"See also InfluxDB: downsampling .","title":"Downsampling data"},{"location":"add-ons/vscode/","text":"Visual Studio Code for Home Assistant With Visual Studio Code for Home Assistant it is really easy to edit your YAML configuration on your Home Assistant machine. I prefer to have my configuration within a version control system, but this add-on provides me with the ability to also edit on server. And I can push my changed back into version control. Installation Installation of this add-on is quite straight forward. The add-on is available as a community add-on within the Home Assistant add-on store. Configuration I just used the stock configuration, which worked fine for me. Extensions Personally, I really prefer the Subliminal color scheme. Which I have installed as an color theme extension and applied to vscode. I also tend to prefer the IntelliJ IDEA keybindings. Git configuration Configuring Git was a bit trickier than I've expected. First of all you'll need your Git private key set up on your Home Assistant server. I had it located within my user's .ssh directory. To get the key into this add-on I've just used this command: sudo cp ~/.ssh/* addons/data/a0d7b954_vscode/.ssh/ After that I had to set up my user and e-mail within the vscode terminal. Something like this: git config --global user.name \"Alex\" git config --global user.email \"alex@example.com\" Finally I was able to effectively use Git from within VSCode.","title":"VSCode"},{"location":"add-ons/vscode/#visual-studio-code-for-home-assistant","text":"With Visual Studio Code for Home Assistant it is really easy to edit your YAML configuration on your Home Assistant machine. I prefer to have my configuration within a version control system, but this add-on provides me with the ability to also edit on server. And I can push my changed back into version control.","title":"Visual Studio Code for Home Assistant"},{"location":"add-ons/vscode/#installation","text":"Installation of this add-on is quite straight forward. The add-on is available as a community add-on within the Home Assistant add-on store.","title":"Installation"},{"location":"add-ons/vscode/#configuration","text":"I just used the stock configuration, which worked fine for me.","title":"Configuration"},{"location":"add-ons/vscode/#extensions","text":"Personally, I really prefer the Subliminal color scheme. Which I have installed as an color theme extension and applied to vscode. I also tend to prefer the IntelliJ IDEA keybindings.","title":"Extensions"},{"location":"add-ons/vscode/#git-configuration","text":"Configuring Git was a bit trickier than I've expected. First of all you'll need your Git private key set up on your Home Assistant server. I had it located within my user's .ssh directory. To get the key into this add-on I've just used this command: sudo cp ~/.ssh/* addons/data/a0d7b954_vscode/.ssh/ After that I had to set up my user and e-mail within the vscode terminal. Something like this: git config --global user.name \"Alex\" git config --global user.email \"alex@example.com\" Finally I was able to effectively use Git from within VSCode.","title":"Git configuration"},{"location":"hardware/ikea-tradfri-open-close-remote/","text":"IKEA TR\u00c5DFRI open/close remote This remote is bundled with the IKEA FYRTUR or KADRILJ, but can be used independently. Device attributes Connectivity This device is connected through Zigbee. Power This device is battery powered with a CR2023 . Battery life Unknown. Factory reset Open the back of the remote and press the pairing button 4 times. Pairing (Phoson) Pairing is done by factory resetting the remote. Pairing should happen automatically within Phoscon. Deconz events 1002 : Open 2002 : Close","title":"IKEA TRADFRI open/close remote"},{"location":"hardware/ikea-tradfri-open-close-remote/#ikea-tradfri-openclose-remote","text":"This remote is bundled with the IKEA FYRTUR or KADRILJ, but can be used independently.","title":"IKEA TR\u00c5DFRI open/close remote"},{"location":"hardware/ikea-tradfri-open-close-remote/#device-attributes","text":"","title":"Device attributes"},{"location":"hardware/ikea-tradfri-open-close-remote/#connectivity","text":"This device is connected through Zigbee.","title":"Connectivity"},{"location":"hardware/ikea-tradfri-open-close-remote/#power","text":"This device is battery powered with a CR2023 .","title":"Power"},{"location":"hardware/ikea-tradfri-open-close-remote/#battery-life","text":"Unknown.","title":"Battery life"},{"location":"hardware/ikea-tradfri-open-close-remote/#factory-reset","text":"Open the back of the remote and press the pairing button 4 times.","title":"Factory reset"},{"location":"hardware/ikea-tradfri-open-close-remote/#pairing-phoson","text":"Pairing is done by factory resetting the remote. Pairing should happen automatically within Phoscon.","title":"Pairing (Phoson)"},{"location":"hardware/ikea-tradfri-open-close-remote/#deconz-events","text":"1002 : Open 2002 : Close","title":"Deconz events"},{"location":"hardware/silvercrest-led-string-lights/","text":"Silvercrest LED String Lights This nice set of Zigbee LED String Lights was sold at Lidl as a new device from their Smart Home line. The device seems to be manufactured by Tuya. Device attributes Connectivity This device is connected through Zigbee. Power This device is powered with a mains power plug. Factory reset Hold the Function (F) key for 5 seconds. When succesful the LED string light will breathe white. Pairing (Phoscon) Pairing is done through resetting the LED string lights. After a reset, pairing should be automatic when the LED string lights are breathing white. Control Control can be done either through deCONZ (Phoscon), deCONZ REST API or Home Assistant. Using the deCONZ REST API gives you the most control. Applying custom effects Through the deCONZ REST API it is possible to apply custom effects with custom colours to the LED string lights. This is currently unsupported within Phoscon or Home Assistant. When you have obtained an API key from the deCONZ REST API (see references below), it is possible to apply an effect. Example requests Twinkle multiple colourss PUT http://home-assistant:40850/api/MY_API_KEY/lights/24/state { \"effect\" : \"twinkle\" , \"effectSpeed\" : 10 , \"effectColours\" : [ [ 172 , 0 , 0 ], [ 128 , 100 , 100 ], ] } Soothing mood light PUT http://home-assistant:40850/api/MY_API_KEY/lights/24/state { \"effect\" : \"carnival\" , \"effectSpeed\" : 10 , \"effectColours\" : [ [ 172 , 0 , 0 ], [ 150 , 0 , 96 ], [ 150 , 0 , 0 ], [ 128 , 100 , 100 ], [ 0 , 128 , 0 ], [ 0 , 0 , 128 ] ] } Note It seems that the maximum number of user adjustable colours is 7. Note The effect speed should be a value from 0 - 100 in percent. Although for some effects the changed speed seems barely noticable or is inverted. Effect list steady (single colour) snow (single colour) rainbow (pre-defined colours) snake twinkle fireworks flag waves updown vintage fading collide strobe sparkles carnival (7 colours) glow (7 colours) Support This device is supported since deCONZ 2.07.01. Notes Sometimes the device can appear as Heiman TS0601 . To fix this, just read the Zigbee Basic attributes from within the deCONZ GUI. References Device manuals deCONZ REST API - Getting Started ebaauw in dresden-elektronik/deconz-rest-plugin!3716","title":"Silvercrest LED String Lights"},{"location":"hardware/silvercrest-led-string-lights/#silvercrest-led-string-lights","text":"This nice set of Zigbee LED String Lights was sold at Lidl as a new device from their Smart Home line. The device seems to be manufactured by Tuya.","title":"Silvercrest LED String Lights"},{"location":"hardware/silvercrest-led-string-lights/#device-attributes","text":"","title":"Device attributes"},{"location":"hardware/silvercrest-led-string-lights/#connectivity","text":"This device is connected through Zigbee.","title":"Connectivity"},{"location":"hardware/silvercrest-led-string-lights/#power","text":"This device is powered with a mains power plug.","title":"Power"},{"location":"hardware/silvercrest-led-string-lights/#factory-reset","text":"Hold the Function (F) key for 5 seconds. When succesful the LED string light will breathe white.","title":"Factory reset"},{"location":"hardware/silvercrest-led-string-lights/#pairing-phoscon","text":"Pairing is done through resetting the LED string lights. After a reset, pairing should be automatic when the LED string lights are breathing white.","title":"Pairing (Phoscon)"},{"location":"hardware/silvercrest-led-string-lights/#control","text":"Control can be done either through deCONZ (Phoscon), deCONZ REST API or Home Assistant. Using the deCONZ REST API gives you the most control.","title":"Control"},{"location":"hardware/silvercrest-led-string-lights/#applying-custom-effects","text":"Through the deCONZ REST API it is possible to apply custom effects with custom colours to the LED string lights. This is currently unsupported within Phoscon or Home Assistant. When you have obtained an API key from the deCONZ REST API (see references below), it is possible to apply an effect.","title":"Applying custom effects"},{"location":"hardware/silvercrest-led-string-lights/#example-requests","text":"","title":"Example requests"},{"location":"hardware/silvercrest-led-string-lights/#twinkle-multiple-colourss","text":"PUT http://home-assistant:40850/api/MY_API_KEY/lights/24/state { \"effect\" : \"twinkle\" , \"effectSpeed\" : 10 , \"effectColours\" : [ [ 172 , 0 , 0 ], [ 128 , 100 , 100 ], ] }","title":"Twinkle multiple colourss"},{"location":"hardware/silvercrest-led-string-lights/#soothing-mood-light","text":"PUT http://home-assistant:40850/api/MY_API_KEY/lights/24/state { \"effect\" : \"carnival\" , \"effectSpeed\" : 10 , \"effectColours\" : [ [ 172 , 0 , 0 ], [ 150 , 0 , 96 ], [ 150 , 0 , 0 ], [ 128 , 100 , 100 ], [ 0 , 128 , 0 ], [ 0 , 0 , 128 ] ] } Note It seems that the maximum number of user adjustable colours is 7. Note The effect speed should be a value from 0 - 100 in percent. Although for some effects the changed speed seems barely noticable or is inverted.","title":"Soothing mood light"},{"location":"hardware/silvercrest-led-string-lights/#effect-list","text":"steady (single colour) snow (single colour) rainbow (pre-defined colours) snake twinkle fireworks flag waves updown vintage fading collide strobe sparkles carnival (7 colours) glow (7 colours)","title":"Effect list"},{"location":"hardware/silvercrest-led-string-lights/#support","text":"This device is supported since deCONZ 2.07.01.","title":"Support"},{"location":"hardware/silvercrest-led-string-lights/#notes","text":"Sometimes the device can appear as Heiman TS0601 . To fix this, just read the Zigbee Basic attributes from within the deCONZ GUI.","title":"Notes"},{"location":"hardware/silvercrest-led-string-lights/#references","text":"Device manuals deCONZ REST API - Getting Started ebaauw in dresden-elektronik/deconz-rest-plugin!3716","title":"References"},{"location":"home-assistant/hacs/","text":"HACS integration HACS (Home Assistant Community Store) is a powerful integration that you can utilize to install custom, unsupported integrations, themes and UI plugins. Installation More information regarding installation of HACS can be found on the Installation page of the HACS documentation. Note If you want to use Git pull with HACS, please set up your Git repository (like below) first before installing HACS. You will make your life significantly easier for yourself! HACS and Git pull add-on HACS can get a bit tricky when you are also using the Git pull add-on, like I do. I was facing merge issues and accidental deletions when pulling changes from Git. Over time I finetuned my set up so I can have the best of both worlds. .gitignore First of all we need to add a couple of lines of code to our .gitignore file located in the root of our Git repository: # HACS .gitignore !**/.managed-by-hacs !.managed-by-hacs Since empty directories are never included in a Git commit, we are going to create these additional rules. Both rules explictly include .managed-by-hacs files within our Git repository. Ensuring that we are not going to delete them when committing to Git. Directories Since HACS uses several directories in our Git configuration for it's data, we are going to add several directories for HACS. I listed a partial view of my file tree below. . \u251c\u2500\u2500 appdaemon \u2502 \u2514\u2500\u2500 apps \u2502 \u2514\u2500\u2500 .managed-by-hacs \u251c\u2500\u2500 configuration.yaml \u251c\u2500\u2500 custom_components \u2502 \u251c\u2500\u2500 hacs \u2502 \u2502 \u2514\u2500\u2500 .managed-by-hacs \u2502 \u2514\u2500\u2500 .managed-by-hacs \u251c\u2500\u2500 .gitignore \u251c\u2500\u2500 netdaemon \u2502 \u2514\u2500\u2500 apps \u2502 \u2514\u2500\u2500 .managed-by-hacs \u251c\u2500\u2500 python_scripts \u2502 \u2514\u2500\u2500 .managed-by-hacs \u251c\u2500\u2500 README.md \u251c\u2500\u2500 themes \u2502 \u2514\u2500\u2500 .managed-by-hacs \u2514\u2500\u2500 www \u2514\u2500\u2500 community \u2514\u2500\u2500 .managed-by-hacs As you can see I added several directories and added .managed-by-hacs placeholder files in them. This ensures that these otherwise empty direcotires are committed into Git. After adding these directories and placeholder files, you can commit these changes to Git. When you have verified your changes in your Home Assistant install, you can now continue installing HACS. Note appdaemon , netdaemon and python_scripts are optional and not enabled by default. They are not required if you don't use them!! configuration.yaml Although enabling HACS is done through an UI integration, you will need to set up configuration.yaml for themes: frontend : themes : !include_dir_merge_named themes You will, possibly, also need to set up your configuration.yaml for your custom_components , but that's up to the integrations that you install. Note Refer to the appdaemon , netdaemon and python_scripts documentation on how to setup those.","title":"HACS"},{"location":"home-assistant/hacs/#hacs-integration","text":"HACS (Home Assistant Community Store) is a powerful integration that you can utilize to install custom, unsupported integrations, themes and UI plugins.","title":"HACS integration"},{"location":"home-assistant/hacs/#installation","text":"More information regarding installation of HACS can be found on the Installation page of the HACS documentation. Note If you want to use Git pull with HACS, please set up your Git repository (like below) first before installing HACS. You will make your life significantly easier for yourself!","title":"Installation"},{"location":"home-assistant/hacs/#hacs-and-git-pull-add-on","text":"HACS can get a bit tricky when you are also using the Git pull add-on, like I do. I was facing merge issues and accidental deletions when pulling changes from Git. Over time I finetuned my set up so I can have the best of both worlds.","title":"HACS and Git pull add-on"},{"location":"home-assistant/hacs/#gitignore","text":"First of all we need to add a couple of lines of code to our .gitignore file located in the root of our Git repository: # HACS .gitignore !**/.managed-by-hacs !.managed-by-hacs Since empty directories are never included in a Git commit, we are going to create these additional rules. Both rules explictly include .managed-by-hacs files within our Git repository. Ensuring that we are not going to delete them when committing to Git.","title":".gitignore"},{"location":"home-assistant/hacs/#directories","text":"Since HACS uses several directories in our Git configuration for it's data, we are going to add several directories for HACS. I listed a partial view of my file tree below. . \u251c\u2500\u2500 appdaemon \u2502 \u2514\u2500\u2500 apps \u2502 \u2514\u2500\u2500 .managed-by-hacs \u251c\u2500\u2500 configuration.yaml \u251c\u2500\u2500 custom_components \u2502 \u251c\u2500\u2500 hacs \u2502 \u2502 \u2514\u2500\u2500 .managed-by-hacs \u2502 \u2514\u2500\u2500 .managed-by-hacs \u251c\u2500\u2500 .gitignore \u251c\u2500\u2500 netdaemon \u2502 \u2514\u2500\u2500 apps \u2502 \u2514\u2500\u2500 .managed-by-hacs \u251c\u2500\u2500 python_scripts \u2502 \u2514\u2500\u2500 .managed-by-hacs \u251c\u2500\u2500 README.md \u251c\u2500\u2500 themes \u2502 \u2514\u2500\u2500 .managed-by-hacs \u2514\u2500\u2500 www \u2514\u2500\u2500 community \u2514\u2500\u2500 .managed-by-hacs As you can see I added several directories and added .managed-by-hacs placeholder files in them. This ensures that these otherwise empty direcotires are committed into Git. After adding these directories and placeholder files, you can commit these changes to Git. When you have verified your changes in your Home Assistant install, you can now continue installing HACS. Note appdaemon , netdaemon and python_scripts are optional and not enabled by default. They are not required if you don't use them!!","title":"Directories"},{"location":"home-assistant/hacs/#configurationyaml","text":"Although enabling HACS is done through an UI integration, you will need to set up configuration.yaml for themes: frontend : themes : !include_dir_merge_named themes You will, possibly, also need to set up your configuration.yaml for your custom_components , but that's up to the integrations that you install. Note Refer to the appdaemon , netdaemon and python_scripts documentation on how to setup those.","title":"configuration.yaml"},{"location":"home-assistant/xiaomi-tokens/","text":"Retrieving Xiaomi Home tokens For several Xiaomi devices it is necessary that you set an access token. This is a 32 character long hash that is generated every time the device first connects to wifi. Applicable devices This is applicable to all Xiaomi Home devices that connect over wifi. In my personal situation I retrieved the tokens of my: Xiaomi Roborock S5 Max Xiaomi Fan 1C Xiaomi Fan 2S Retrieving your token(s) Currently it is impossible to retrieve this token officially, but there is a workaround available. Install the latest Mi Home app from the Google Play Store Login with your Xiaomi account Set up your Xiaomi device Uninstall Mi Home from your Android device Install Mi Home 5.4.49 Again login with your Xiaomi account Set up ADB access to your Android device Use adb shell to get into the shell of your Android device Retrieve the tokens through cat /sdcard/SmartHome/logs/plug_DeviceManager/*.log Note Replace the Xiaomi Mi Home app afterwards. Older versions may not work correctly with new(er) devices.","title":"Xiaomi Tokens"},{"location":"home-assistant/xiaomi-tokens/#retrieving-xiaomi-home-tokens","text":"For several Xiaomi devices it is necessary that you set an access token. This is a 32 character long hash that is generated every time the device first connects to wifi.","title":"Retrieving Xiaomi Home tokens"},{"location":"home-assistant/xiaomi-tokens/#applicable-devices","text":"This is applicable to all Xiaomi Home devices that connect over wifi. In my personal situation I retrieved the tokens of my: Xiaomi Roborock S5 Max Xiaomi Fan 1C Xiaomi Fan 2S","title":"Applicable devices"},{"location":"home-assistant/xiaomi-tokens/#retrieving-your-tokens","text":"Currently it is impossible to retrieve this token officially, but there is a workaround available. Install the latest Mi Home app from the Google Play Store Login with your Xiaomi account Set up your Xiaomi device Uninstall Mi Home from your Android device Install Mi Home 5.4.49 Again login with your Xiaomi account Set up ADB access to your Android device Use adb shell to get into the shell of your Android device Retrieve the tokens through cat /sdcard/SmartHome/logs/plug_DeviceManager/*.log Note Replace the Xiaomi Mi Home app afterwards. Older versions may not work correctly with new(er) devices.","title":"Retrieving your token(s)"},{"location":"homelab/plex-transcoding-fix/","text":"Plex QSV transcoding fix When utilizing Plex transcoding with Quick Sync Video the output can be broken on newer Intel systems. Which is also the case on my Intel J4105 processor. However there is a quick fix available. Note This issue seems resolved with Plex Media Server version 1.21.1.3766. Note Usage of Quick Sync Video is a Plex Pass feature. Removing iHD driver If you simply remove the iHD driver on these newer Intel platforms, Plex utilizes the older i965 driver. Perhaps performance isn't that good, but it is still better than using the CPU for transcoding. Removing this file is as simple as: sudo rm -f /usr/lib/plexmediaserver/lib/dri/iHD_drv_video.so sudo systemctl restart plexmediaserver.service Systemctl unit file To automate this process I installed a simple Systemctl unit file onto my home server. [Unit] Description=Remove Plex's iHD driver Before=plexmediaserver.service [Service] Type=oneshot ExecStart=/usr/bin/rm -f /usr/lib/plexmediaserver/lib/dri/iHD_drv_video.so TimeoutStopSec=5 User=root [Install] WantedBy=multi-user.target plexmediaserver.service To install this, put the contents above into /usr/lib/systemd/system/remove-ihd-driver.service , and run the appropiate systemctl commands below. sudo systemctl daemon-reload sudo systemctl start remove-ihd-driver sudo systemctl enable remove-ihd-driver","title":"Plex QSV transcoding fix"},{"location":"homelab/plex-transcoding-fix/#plex-qsv-transcoding-fix","text":"When utilizing Plex transcoding with Quick Sync Video the output can be broken on newer Intel systems. Which is also the case on my Intel J4105 processor. However there is a quick fix available. Note This issue seems resolved with Plex Media Server version 1.21.1.3766. Note Usage of Quick Sync Video is a Plex Pass feature.","title":"Plex QSV transcoding fix"},{"location":"homelab/plex-transcoding-fix/#removing-ihd-driver","text":"If you simply remove the iHD driver on these newer Intel platforms, Plex utilizes the older i965 driver. Perhaps performance isn't that good, but it is still better than using the CPU for transcoding. Removing this file is as simple as: sudo rm -f /usr/lib/plexmediaserver/lib/dri/iHD_drv_video.so sudo systemctl restart plexmediaserver.service","title":"Removing iHD driver"},{"location":"homelab/plex-transcoding-fix/#systemctl-unit-file","text":"To automate this process I installed a simple Systemctl unit file onto my home server. [Unit] Description=Remove Plex's iHD driver Before=plexmediaserver.service [Service] Type=oneshot ExecStart=/usr/bin/rm -f /usr/lib/plexmediaserver/lib/dri/iHD_drv_video.so TimeoutStopSec=5 User=root [Install] WantedBy=multi-user.target plexmediaserver.service To install this, put the contents above into /usr/lib/systemd/system/remove-ihd-driver.service , and run the appropiate systemctl commands below. sudo systemctl daemon-reload sudo systemctl start remove-ihd-driver sudo systemctl enable remove-ihd-driver","title":"Systemctl unit file"},{"location":"homelab/qnap-disk-spindown/","text":"Enabling QNAP disk spindown I like to enable disk spindown within my NAS to save on power consumption. This behaviour should be enabled by default, but in my case it wasn't working correctly. After some time scouring the internet, I found that many users were having the same issues. With some online resources I found a way to truly enable QNAP disk spindown. Note This is advanced usage. Please bear in mind that this modifies your default NAS behaviour. Requirements QNAP NAS NVMe SSD installed into your NAS Disable QTS storage QTS creates a RAID1 array across all your drives inside of your NAS for it's OS storage. Initially I thought this was a clever idea. But it can (and will) prevent your drives from spindown. Even if you have a NVMe SSD installed. Since SSD's rarely die from wear in normal use, I decided to disable this RAID1 array most of the time. However we rebuild this array once a day to keep our data synced to all our drives. Just in case a drive failure occurs. More on that later. Note I've added this script to my /shares/scripts/ directory, but it can also be placed inside of your /root/ (or ~ ) directory. Finding out which drives to disable Just run cat /proc/mdstat which would return something like this: Personalities : [linear] [raid0] [raid1] [raid10] [raid6] [raid5] [raid4] [multipath] ... md13 : active raid1 sdd[3] sdb[2] sda[1] nvme0n1p4[0] 458880 blocks super 1.0 [32/1] [U_______________________________] bitmap: 1/1 pages [4KB], 65536KB chunk md9 : active raid1 sdd[3] sdb[2] sda[1] nvme0n1p4[0] 530048 blocks super 1.0 [32/1] [U_______________________________] bitmap: 1/1 pages [4KB], 65536KB chunk Since I've installed an NVMe drive, I only want to retain that drive for my QTS storage. Remember the other drives, because you will need to edit the scripts below to fit your storage solution. Disconnecting the QTS RAID1 array First up we add a script to disconnect our internal QTS RAID1 array. #!/bin/bash HDDS = \"sda sdb sdd\" errquit () { STATUS = 1 _errlog \" $@ \" exit ${ STATUS } } echo \"Disconnecting hdd's from /dev/md9 array\" for disk in ${ HDDS } ; do if [ ! -e /dev/ ${ disk } ] ; then errquit \"Could not find /dev/ ${ disk } \" else mdadm /dev/md9 --fail /dev/ ${ disk } 1 fi done echo \"Disconneting hdd's from /dev/md13 array\" for disk in ${ HDDS } ; do if [ ! -e /dev/ ${ disk } ] ; then errquit \"Could not find /dev/ ${ disk } \" else mdadm /dev/md13 --fail /dev/ ${ disk } 4 fi done Note You should modify the HDDS parameter to suit your NAS and drive configuration. Rebuilding the QTS RAID1 array Second up, we add a script to rebuild our QTS array once a day for data integrity should my NVMe drive fail. #!/bin/bash HDDS = \"sda sdb sdd\" errquit () { STATUS = 1 _errlog \" $@ \" exit 1 } echo \"Rebuilding hdd's to /dev/md9 array\" for disk in ${ HDDS } ; do if [ ! -e /dev/ ${ disk } ] ; then errquit \"Could not find /dev/ ${ disk } \" else mdadm /dev/md9 --re-add /dev/ ${ disk } 1 fi done echo \"Rebuilding hdd's to /dev/md13 array\" for disk in ${ HDDS } ; do if [ ! -e /dev/ ${ disk } ] ; then errquit \"Could not find /dev/ ${ disk } \" else mdadm /dev/md13 --re-add /dev/ ${ disk } 4 fi done Disable swap Since I've added 8GB of RAM to my NAS, I decided to disable swap memory. Because swap is also shared between (hard)drives. You could also add a swap file on the NVMe storage if you still want swap enabled. echo \"Turning system swap off\" swapoff -a Autorun To get this all going, you can edit QTS's autorun file. Editing this file is different on different NAS devices. You can check QNAP's documentation on how to edit this file on your NAS. Editing autorun mount $( /sbin/hal_app --get_boot_pd port_id = 0 ) 6 /tmp/config vi /tmp/config/autorun.sh chmod +x /tmp/config/autorun.sh umount /tmp/config Autorun script if crontab -l | grep -q 'rebuild_internal_raid' ; then # Nothing to do; /etc/config/ is on a persistent storage and was already modified : else echo \"15 10 * * * /share/scripts/rebuild_internal_raid.sh\" >> /etc/config/crontab crontab /etc/config/crontab && /etc/init.d/crond.sh restart fi if crontab -l | grep -q 'disconnect_internal_raid' ; then # Nothing to do; /etc/config/ is on a persistent storage and was already modified : else echo \"30 10 * * * /share/scripts/disconnect_internal_raid.sh\" >> /etc/config/crontab crontab /etc/config/crontab && /etc/init.d/crond.sh restart fi exec /share/scripts/disconnect_internal_raid.sh echo \"Turning system swap off\" swapoff -a References https://www.reddit.com/r/qnap/comments/fhh61n/new_ts328_hdds_not_spinning_down_qnap_say_its/ https://forum.qnap.com/viewtopic.php?t=130788 https://wiki.qnap.com/wiki/Add_items_to_crontab","title":"Enabling QNAP disk spindown"},{"location":"homelab/qnap-disk-spindown/#enabling-qnap-disk-spindown","text":"I like to enable disk spindown within my NAS to save on power consumption. This behaviour should be enabled by default, but in my case it wasn't working correctly. After some time scouring the internet, I found that many users were having the same issues. With some online resources I found a way to truly enable QNAP disk spindown. Note This is advanced usage. Please bear in mind that this modifies your default NAS behaviour.","title":"Enabling QNAP disk spindown"},{"location":"homelab/qnap-disk-spindown/#requirements","text":"QNAP NAS NVMe SSD installed into your NAS","title":"Requirements"},{"location":"homelab/qnap-disk-spindown/#disable-qts-storage","text":"QTS creates a RAID1 array across all your drives inside of your NAS for it's OS storage. Initially I thought this was a clever idea. But it can (and will) prevent your drives from spindown. Even if you have a NVMe SSD installed. Since SSD's rarely die from wear in normal use, I decided to disable this RAID1 array most of the time. However we rebuild this array once a day to keep our data synced to all our drives. Just in case a drive failure occurs. More on that later. Note I've added this script to my /shares/scripts/ directory, but it can also be placed inside of your /root/ (or ~ ) directory.","title":"Disable QTS storage"},{"location":"homelab/qnap-disk-spindown/#finding-out-which-drives-to-disable","text":"Just run cat /proc/mdstat which would return something like this: Personalities : [linear] [raid0] [raid1] [raid10] [raid6] [raid5] [raid4] [multipath] ... md13 : active raid1 sdd[3] sdb[2] sda[1] nvme0n1p4[0] 458880 blocks super 1.0 [32/1] [U_______________________________] bitmap: 1/1 pages [4KB], 65536KB chunk md9 : active raid1 sdd[3] sdb[2] sda[1] nvme0n1p4[0] 530048 blocks super 1.0 [32/1] [U_______________________________] bitmap: 1/1 pages [4KB], 65536KB chunk Since I've installed an NVMe drive, I only want to retain that drive for my QTS storage. Remember the other drives, because you will need to edit the scripts below to fit your storage solution.","title":"Finding out which drives to disable"},{"location":"homelab/qnap-disk-spindown/#disconnecting-the-qts-raid1-array","text":"First up we add a script to disconnect our internal QTS RAID1 array. #!/bin/bash HDDS = \"sda sdb sdd\" errquit () { STATUS = 1 _errlog \" $@ \" exit ${ STATUS } } echo \"Disconnecting hdd's from /dev/md9 array\" for disk in ${ HDDS } ; do if [ ! -e /dev/ ${ disk } ] ; then errquit \"Could not find /dev/ ${ disk } \" else mdadm /dev/md9 --fail /dev/ ${ disk } 1 fi done echo \"Disconneting hdd's from /dev/md13 array\" for disk in ${ HDDS } ; do if [ ! -e /dev/ ${ disk } ] ; then errquit \"Could not find /dev/ ${ disk } \" else mdadm /dev/md13 --fail /dev/ ${ disk } 4 fi done Note You should modify the HDDS parameter to suit your NAS and drive configuration.","title":"Disconnecting the QTS RAID1 array"},{"location":"homelab/qnap-disk-spindown/#rebuilding-the-qts-raid1-array","text":"Second up, we add a script to rebuild our QTS array once a day for data integrity should my NVMe drive fail. #!/bin/bash HDDS = \"sda sdb sdd\" errquit () { STATUS = 1 _errlog \" $@ \" exit 1 } echo \"Rebuilding hdd's to /dev/md9 array\" for disk in ${ HDDS } ; do if [ ! -e /dev/ ${ disk } ] ; then errquit \"Could not find /dev/ ${ disk } \" else mdadm /dev/md9 --re-add /dev/ ${ disk } 1 fi done echo \"Rebuilding hdd's to /dev/md13 array\" for disk in ${ HDDS } ; do if [ ! -e /dev/ ${ disk } ] ; then errquit \"Could not find /dev/ ${ disk } \" else mdadm /dev/md13 --re-add /dev/ ${ disk } 4 fi done","title":"Rebuilding the QTS RAID1 array"},{"location":"homelab/qnap-disk-spindown/#disable-swap","text":"Since I've added 8GB of RAM to my NAS, I decided to disable swap memory. Because swap is also shared between (hard)drives. You could also add a swap file on the NVMe storage if you still want swap enabled. echo \"Turning system swap off\" swapoff -a","title":"Disable swap"},{"location":"homelab/qnap-disk-spindown/#autorun","text":"To get this all going, you can edit QTS's autorun file. Editing this file is different on different NAS devices. You can check QNAP's documentation on how to edit this file on your NAS.","title":"Autorun"},{"location":"homelab/qnap-disk-spindown/#editing-autorun","text":"mount $( /sbin/hal_app --get_boot_pd port_id = 0 ) 6 /tmp/config vi /tmp/config/autorun.sh chmod +x /tmp/config/autorun.sh umount /tmp/config","title":"Editing autorun"},{"location":"homelab/qnap-disk-spindown/#autorun-script","text":"if crontab -l | grep -q 'rebuild_internal_raid' ; then # Nothing to do; /etc/config/ is on a persistent storage and was already modified : else echo \"15 10 * * * /share/scripts/rebuild_internal_raid.sh\" >> /etc/config/crontab crontab /etc/config/crontab && /etc/init.d/crond.sh restart fi if crontab -l | grep -q 'disconnect_internal_raid' ; then # Nothing to do; /etc/config/ is on a persistent storage and was already modified : else echo \"30 10 * * * /share/scripts/disconnect_internal_raid.sh\" >> /etc/config/crontab crontab /etc/config/crontab && /etc/init.d/crond.sh restart fi exec /share/scripts/disconnect_internal_raid.sh echo \"Turning system swap off\" swapoff -a","title":"Autorun script"},{"location":"homelab/qnap-disk-spindown/#references","text":"https://www.reddit.com/r/qnap/comments/fhh61n/new_ts328_hdds_not_spinning_down_qnap_say_its/ https://forum.qnap.com/viewtopic.php?t=130788 https://wiki.qnap.com/wiki/Add_items_to_crontab","title":"References"},{"location":"homelab/qnap-linux-mount/","text":"Mounting QNAP disks in Debian Linux I recently migrated to a QNAP NAS from an old DIY NAS for most of my home data. When starting to copy over my first batch of data I worked out that the data transfer was going to take about 12 - 18 hours on my 1GBps home network... This was unacceptable to me, so I tried mounting my new shiny QNAP NAS disk (readily formatted) inside my old DIY NAS to speed up the transfer. After doing this, the transfer was about 6 times faster than copying all data over my network. All in all this was a bit harder than anticipated, so I documented my steps. Note This guide may not work for every RAID setup, but can provide a simple reference. QNAP side On the QNAP side I had created a Single Volume with a single disk, no RAID whatsoever. On that disk I created a shared folder with a placeholder file that I could recognize for testing the mount. I did not opt for a Storage Pool, because data redundency was not my primary goal. Debian Linux side Within Debian I had to install two packages first. Note All these steps require root ( sudo )! apt update apt install -y mdadm lvm2 We need both mdadm and lvm2 for managing the QNAP resource. After which we can scan for both RAID devices and LVM devices. mdadm --assemble --scan lvscan The commands above are probably not mandatory, but they seem to get something going. Now we can look at which Volume Groups (VG) are found within the system. vgdisplay In my setup, this returned volume group vg289 . I also noticed this with the lvscan command, but this is a bit more verbose and human readable. Now that we know the volume group (VG) name, we can activate it. vgchange -a y vg289 This command will activate the volume group, if all goes well. I re-ran the lvscan command to check if the volume group was correctly activated and to look up the logical volume (LV) I wanted to utilize. lvscan ACTIVE '/dev/vg289/lv545' [ < 37 .28 GiB ] inherit ACTIVE '/dev/vg289/lv2' [ 3 .59 TiB ] inherit As you can probably tell, the lv2 volume was the one I wanted to use. Since the LV was now active, I can mount it. mkdir -p /mnt/qnap mount /dev/vg289/lv2/ /mnt/qnap Et voila. This mounted my QNAP locally on my Linux box. Note This guide will also work with Debian derivatives, such as Ubuntu Linux References https://forum.qnap.com/viewtopic.php?t=93862 https://superuser.com/a/666034","title":"Mounting QNAP disks in Debian Linux"},{"location":"homelab/qnap-linux-mount/#mounting-qnap-disks-in-debian-linux","text":"I recently migrated to a QNAP NAS from an old DIY NAS for most of my home data. When starting to copy over my first batch of data I worked out that the data transfer was going to take about 12 - 18 hours on my 1GBps home network... This was unacceptable to me, so I tried mounting my new shiny QNAP NAS disk (readily formatted) inside my old DIY NAS to speed up the transfer. After doing this, the transfer was about 6 times faster than copying all data over my network. All in all this was a bit harder than anticipated, so I documented my steps. Note This guide may not work for every RAID setup, but can provide a simple reference.","title":"Mounting QNAP disks in Debian Linux"},{"location":"homelab/qnap-linux-mount/#qnap-side","text":"On the QNAP side I had created a Single Volume with a single disk, no RAID whatsoever. On that disk I created a shared folder with a placeholder file that I could recognize for testing the mount. I did not opt for a Storage Pool, because data redundency was not my primary goal.","title":"QNAP side"},{"location":"homelab/qnap-linux-mount/#debian-linux-side","text":"Within Debian I had to install two packages first. Note All these steps require root ( sudo )! apt update apt install -y mdadm lvm2 We need both mdadm and lvm2 for managing the QNAP resource. After which we can scan for both RAID devices and LVM devices. mdadm --assemble --scan lvscan The commands above are probably not mandatory, but they seem to get something going. Now we can look at which Volume Groups (VG) are found within the system. vgdisplay In my setup, this returned volume group vg289 . I also noticed this with the lvscan command, but this is a bit more verbose and human readable. Now that we know the volume group (VG) name, we can activate it. vgchange -a y vg289 This command will activate the volume group, if all goes well. I re-ran the lvscan command to check if the volume group was correctly activated and to look up the logical volume (LV) I wanted to utilize. lvscan ACTIVE '/dev/vg289/lv545' [ < 37 .28 GiB ] inherit ACTIVE '/dev/vg289/lv2' [ 3 .59 TiB ] inherit As you can probably tell, the lv2 volume was the one I wanted to use. Since the LV was now active, I can mount it. mkdir -p /mnt/qnap mount /dev/vg289/lv2/ /mnt/qnap Et voila. This mounted my QNAP locally on my Linux box. Note This guide will also work with Debian derivatives, such as Ubuntu Linux","title":"Debian Linux side"},{"location":"homelab/qnap-linux-mount/#references","text":"https://forum.qnap.com/viewtopic.php?t=93862 https://superuser.com/a/666034","title":"References"},{"location":"installation/host-system/","text":"Home Assistant host and install Hardware I've installed Home Assistant on an Intel NUC-like device, the Gigabyte Brix GB-BLCE-4105 with the following specs: Processor Intel Celeron J4105 (quad core) Memory Corsair ValueSelect 8GB DDR4 SO-DIMM RAM (2x4GB) Storage Samsung 60GB SLC SSD I chose the Gigabyte box instead of an Intel NUC because of the quad core Celeron processor. The J4105 is far newer than the (then alternative) J3455 and faster than the dual core J4005. Both having about the same price. For a slightly higher cost I put in 8GB of DDR4, which can be quite overkill as 4GB is sufficient for my complete system. Finally I settled on an old enterprise Samsung 60GB SLC SSD. Not the fastest drive in the world, but really robust because of the SLC memory that is used. I expect this drive to work for at least another 20 years. Software For my use case I have a custom Home Assistant install based on top of Debian Linux. I chose Debian Linux, because it is lighter and more barebones than for instance Ubuntu Linux. Also I'm familiar with Debian Linux because of the Raspbian distribution that I used earlier. Debian install The Debian installation is fairly straight forward with only a few steps involved. You will need an USB thumb drive and a working internet connection. Download the latest stable version of Debian (server) from the non-free firmware repo . This version contains all the proprietary kernel modules needed for network connectivity Put this ISO onto an USB thumb drive (ith the balenaEtcher utility) Insert the thumb drive into the target device and boot the machine with the USB drive Follow the network install of Debian I've ignored the root user I didn't set up an X environment Additionally installed SSH server Used the complete disk for provisioning Additional packages After the install of Debian was complete. I opted to install some of my favorite CLI utilities: sudo apt-get update sudo apt-get install aptitude avahi-daemon bash curl dbus dnsutils git htop jq ncdu nmon socat sshpass vim Note Some of these packages are also required by Home Assistant later. Additional settings Swappiness I lower the swappiness of the system, to prevent using swap. # Set up sudo sysctl -w vm.swappiness = 5 sudo echo \"vm.swappiness=5\" >> /etc/sysctl.conf # Check if correctly configured sysctl vm.swappiness cat /etc/sysctl.conf Root user We didn't set up a root user during install. This is fine, since we can use sudo , but prevents us from getting into safe mode when \ud83d\udca9 hits the fan. So we set up a password for the root user. sudo su passwd Docker install It's quite easy to install Docker. We use the official documentation as a reference for this step. # First we change to root mode sudo -i apt update apt install apt-transport-https ca-certificates curl gnupg-agent software-properties-common curl -fsSL https://download.docker.com/linux/debian/gpg | apt-key add - add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/debian $( lsb_release -cs ) stable\" apt update apt install docker-ce docker-ce-cli containerd.io # This is optional, but I like to know for sure that the Docker unit file is enabled systemctl enable docker # Finally we exit root mode exit Note Before installing Docker, check if the steps above are still relevant! Docker group (optional) We can also add ourselves to the Docker group. This removes the requirement of using sudo when we want to do anything with the Docker cli. This is an optional step. sudo groupadd docker sudo usermod -aG docker $USER CGroup policies (optional) On my system, the CGroup policies were not set. I had to amend my Grub bootloader, by adding/replacing the following line in /etc/default/grub : GRUB_CMDLINE_LINUX=\"cgroup_enable=memory swapaccount=1\" After which you can reload grub with sudo update-grub and reboot your system to have it take affect. Docker compose (optional) I like to have Docker compose installed. Completely optional, but quite easy to do, according to the official documentation : sudo curl -L \"https://github.com/docker/compose/releases/download/1.27.4/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose Home Assistant installation We do a simple supervised installation of Home Assistant: sudo -i curl -sL https://raw.githubusercontent.com/home-assistant/supervised-installer/master/installer.sh | bash -s exit That's it! This completes a complete Home Assistant install on your new, spanking machine. Check out Home Assistant on: http://[LOCAL_IP_ADDRESS]:8123 .","title":"Custom installation"},{"location":"installation/host-system/#home-assistant-host-and-install","text":"","title":"Home Assistant host and install"},{"location":"installation/host-system/#hardware","text":"I've installed Home Assistant on an Intel NUC-like device, the Gigabyte Brix GB-BLCE-4105 with the following specs: Processor Intel Celeron J4105 (quad core) Memory Corsair ValueSelect 8GB DDR4 SO-DIMM RAM (2x4GB) Storage Samsung 60GB SLC SSD I chose the Gigabyte box instead of an Intel NUC because of the quad core Celeron processor. The J4105 is far newer than the (then alternative) J3455 and faster than the dual core J4005. Both having about the same price. For a slightly higher cost I put in 8GB of DDR4, which can be quite overkill as 4GB is sufficient for my complete system. Finally I settled on an old enterprise Samsung 60GB SLC SSD. Not the fastest drive in the world, but really robust because of the SLC memory that is used. I expect this drive to work for at least another 20 years.","title":"Hardware"},{"location":"installation/host-system/#software","text":"For my use case I have a custom Home Assistant install based on top of Debian Linux. I chose Debian Linux, because it is lighter and more barebones than for instance Ubuntu Linux. Also I'm familiar with Debian Linux because of the Raspbian distribution that I used earlier.","title":"Software"},{"location":"installation/host-system/#debian-install","text":"The Debian installation is fairly straight forward with only a few steps involved. You will need an USB thumb drive and a working internet connection. Download the latest stable version of Debian (server) from the non-free firmware repo . This version contains all the proprietary kernel modules needed for network connectivity Put this ISO onto an USB thumb drive (ith the balenaEtcher utility) Insert the thumb drive into the target device and boot the machine with the USB drive Follow the network install of Debian I've ignored the root user I didn't set up an X environment Additionally installed SSH server Used the complete disk for provisioning","title":"Debian install"},{"location":"installation/host-system/#additional-packages","text":"After the install of Debian was complete. I opted to install some of my favorite CLI utilities: sudo apt-get update sudo apt-get install aptitude avahi-daemon bash curl dbus dnsutils git htop jq ncdu nmon socat sshpass vim Note Some of these packages are also required by Home Assistant later.","title":"Additional packages"},{"location":"installation/host-system/#additional-settings","text":"","title":"Additional settings"},{"location":"installation/host-system/#swappiness","text":"I lower the swappiness of the system, to prevent using swap. # Set up sudo sysctl -w vm.swappiness = 5 sudo echo \"vm.swappiness=5\" >> /etc/sysctl.conf # Check if correctly configured sysctl vm.swappiness cat /etc/sysctl.conf","title":"Swappiness"},{"location":"installation/host-system/#root-user","text":"We didn't set up a root user during install. This is fine, since we can use sudo , but prevents us from getting into safe mode when \ud83d\udca9 hits the fan. So we set up a password for the root user. sudo su passwd","title":"Root user"},{"location":"installation/host-system/#docker-install","text":"It's quite easy to install Docker. We use the official documentation as a reference for this step. # First we change to root mode sudo -i apt update apt install apt-transport-https ca-certificates curl gnupg-agent software-properties-common curl -fsSL https://download.docker.com/linux/debian/gpg | apt-key add - add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/debian $( lsb_release -cs ) stable\" apt update apt install docker-ce docker-ce-cli containerd.io # This is optional, but I like to know for sure that the Docker unit file is enabled systemctl enable docker # Finally we exit root mode exit Note Before installing Docker, check if the steps above are still relevant!","title":"Docker install"},{"location":"installation/host-system/#docker-group-optional","text":"We can also add ourselves to the Docker group. This removes the requirement of using sudo when we want to do anything with the Docker cli. This is an optional step. sudo groupadd docker sudo usermod -aG docker $USER","title":"Docker group (optional)"},{"location":"installation/host-system/#cgroup-policies-optional","text":"On my system, the CGroup policies were not set. I had to amend my Grub bootloader, by adding/replacing the following line in /etc/default/grub : GRUB_CMDLINE_LINUX=\"cgroup_enable=memory swapaccount=1\" After which you can reload grub with sudo update-grub and reboot your system to have it take affect.","title":"CGroup policies (optional)"},{"location":"installation/host-system/#docker-compose-optional","text":"I like to have Docker compose installed. Completely optional, but quite easy to do, according to the official documentation : sudo curl -L \"https://github.com/docker/compose/releases/download/1.27.4/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose","title":"Docker compose (optional)"},{"location":"installation/host-system/#home-assistant-installation","text":"We do a simple supervised installation of Home Assistant: sudo -i curl -sL https://raw.githubusercontent.com/home-assistant/supervised-installer/master/installer.sh | bash -s exit","title":"Home Assistant installation"},{"location":"installation/host-system/#thats-it","text":"This completes a complete Home Assistant install on your new, spanking machine. Check out Home Assistant on: http://[LOCAL_IP_ADDRESS]:8123 .","title":"That's it!"}]}